Overview
========

This file gives an overview of IPython1.  IPython1 has a sophisticated and powerful architecture for parallel and distributed computing.  This architecture abstracts out parallelism in a very general way.  This enables ipython1 to support many different styles of parallelism including::

1. Single program, multiple data (SPMD), message passing applications.
2. Task farming.
3. General Multiple Program, Multiple Data (MPMD) parallelism.
4. Data parallel.
5. Combinations of these approaches.
5. Custom user defined approaches.

For installation instructions, see the INSTALL file in this directory.

The IPython1 architecture consists of three components: the IPython Engine, the IPython Controller and various Controller Clients.

IPython Engine
--------------

The IPython Engine is a Python instance that takes Python commands over a
network connection.  Eventually, the IPython Engine will be a full IPython
interpreter, but for now, it is a regular Python interpreter.  The Engine can also handle incoming and outgoing Python objects sent over a network connection.  When multiple Engines are started, parallel and distributed computing becomes possible.  An important feature of an IPython Engine is that it blocks while user code is being executed.  Read on for how the Controller solves this problem to expose a clean asynchronous API to the user.

IPython Controller
------------------

The IPython Controller provides an interface for working with a set of Engines.  At an abstract level, the Controller is an object and process to which IPython Engines can connect.  For each connected Engine, the Controller manages a queue of commands in incoming/outgoing Python objects.  While the Engines themselves block when user code is run, the Controller hides that from the user to provide a fully asynchronous interface to a set of computing resources.  Because the Controller listens on a network port for Engines to connect to it, it must be started before any Engines are started.  

The Controller also provides a single point of contact for users who wish to
utilize the Engines connected to the Controller.  There are different ways 
(ways=interfaces) of working with a controller.  Currently we have two
default interfaces to the controller:  RemoteController and TaskController.

Additional interfaces can be added to to enable other styles of parallelism.

Controller Clients
------------------

For each controller interface, there is a corresponding client.  These clients
allow users to interact with a set of engines through the interface that
the controller exposes.

Getting Started
===============

To use IPython1 for parallel computing, you need to start one instance of the
controller and one or more instances of the engine.  The controller and each
engine can run on different machines or on the same machine.  Because of this,
there are many different possibilities for setting up the ip addresses and
ports used by the various processes.

Starting the controller and engine on your local machine
--------------------------------------------------------

This is the simplest configuration that can be used and is useful for testing
the system and on machines that have multiple cores and/or multple CPUs.  The
easiest way of doing this is using the ``ipcluster`` command::

	ipcluster -n 4
	
This will start an IPython controller and then 4 engines that connect to the 
controller.  Lastly, the script will print out the Python commands that you
can use to connect to the controller.  It is that easy.

Underneath the hood, the ``ipcluster`` script uses two other top-level scripts
that you can also use yourself.  These scripts are ``ipcontroller``, which
starts the controller and ``ipengine`` which starts an engine.  To use these
scripts to start things on your local machine, do the following.

First start the controller::

	ipcontroller &
	
Next, start however many instances of the engine you want to use::

	ipengine &

*WARNING*: the order of the above operations is very important.  You *must*
 start the controller before the engines, since the engines connect to the
 controller as they get started.

On some platforms you may need to give these commands in the form
``(ipcontroller &)`` and ``(ipengine &)`` for them to work properly.  The
engines should start and automatically connect to the controller on the default
ports, which are chosen for this type of setup.  The logs are fairly verbose
and you should see various messages about the engines being registered with the
controller.  You are now ready to use the controller and engines from IPython.

Starting the controller and engines on different machines
---------------------------------------------------------

To start the engines and controller on different machines you simply need to
specify the ip addresses where the controller is running.  Let's say you want
to start the controller on host0 and the engines on hosts1 - host16.  First
start the controller on host0::

	host0> ipcontroller &
	
Next, start the engines on host1 - host16 specifying the where the controller
is running::

	host1> ipengine --controller-ip=host0 &
	
Repeat this on host2 - host16 and you should be ready to go.

Specifying custom ports
-----------------------

The controller can be configured to use different ports that the default.
Both the controller and engines must be told to use the same port::

	ipcontroller --engine-port=10001              # listen on 10001
	ipengine --controller-port=10001              # connect to 10001
	
Starting engines using mpirun
-----------------------------

The IPython engine can be started using mpirun/mpiexec, even if the engines
don't call MPI_Init() or use the MPI API.  This is supported on modern MPI
implementations like OpenMPI.  On a system with MPI installed you can do::

	mpirun -n 4 ipengine --controller-port=10000 --controller-ip=host0
	

Using the Controller and Engines from a Client
==============================================

The best source of documentation about how to use the controller and engines
is the docstrings of kernel modules.  Eventually, we will provide more 
details in this readme.

The RemoteController client
---------------------------

Once a controller and engines are running you can connect to it using the 
`RemoteController` class.  This class provides a client for the MultiEngine
interface.  Don't worry about what this means for now, it will become
clear as you use it.

First import the ipython1 client and create a RemoteController instance::

	>>> import ipython1.kernel.api as kernel
	>>> rc = kernel.RemoteController(('127.0.0.1',10105))
	
Now you can see what engines are registered with the controller::

	>>> rc.get_ids()
	[0,1,2,3]

If this works, you are ready to go.  Start next by looking at the docstrings
for the following commands:

1. execute
2. push/pull
3. scatter/gather

The TaskController client
-------------------------

The TaskController interface to the controller presents the engines as a fault
tolerant, dynamic load-balancing system.  You can even have a
RemoteController and a TaskController simultaneously connected to the same
controller.  But, be warned, the tasks will share the namespace on the 
engines with the RemoteController.  But, this is actually a feature that allows
you to do some really nice things.

First create a TaskController objects::

	>>> import ipython1.kernel.api as kernel
	>>> tc = kernel.TaskController(('127.0.0.1',10113))
	
Note that the port is different than the RemoteController.  Now you can 
start submitting tasks by passing instances of kernel.Task to tc.run.

It is best to check out the examples of using the task farming stuff in 
ipython1/doc/examples.