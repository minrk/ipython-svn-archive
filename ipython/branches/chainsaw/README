Date:  9/5/2005
Author:  Brian E. Granger (bgranger@scu.edu)

This file gives an overview of the ipython kernel and the ipython kernel
interface.

For installation instructions, see the INSTALL file in this directory.

= Overview =

The ipython kernel opens up the door for the following:

1.  Interactive parallel computation in python.  

2.  A separation (into two or more processes) of the python user interface
    and the executetion of python code.
    
3.  Seamless support for the interactive use of multiple GUI toolkits.

4.  Collaborative computing.

The ipython kernel actually consists of two layers: the kernel and the kernel
client.  The kernel is run in a separate process and consists of a
fully functional python interpreter that listen for python commands on a 
network port rather that a command line.  The kernel client is run by
the user in a separate python interpreter.  The kernel client 
consists of a set of python objects that allow the user to interact with one 
or more kernels simultaneously.  

NOTE:   If you run code on the kernel that i) calls C/C++/fortran and ii)
        does not release Python's Global Interpreter Lock (GIL), the kernel
        will become unresponsive while the code runs.  We are fixing this
        problem in a future release.

= Basic Usage =


== Starting the kernel ==

The basic ipython kernel is contained in the module kernel.py.  The 
kernel can be started using the command:

    ipkernel

NOTE: It may not be possible to run the kernel in the background currently. 
Thus if you try python kernel.py &, the kernel will not work.  This has to do with the deep inner workings of Twisted.  In the future you will be able to do
this.

Be default, the kernel listens on TCP port 10105.  To specify what TCP port
the kernel should listen on, use the -p (or --port) option:

    ipkernel --port 10106

For security reasons, the kernel can be configured to allow or deny connections
from specific ip addresses.  The default is to allow connections only from the
localhost (127.0.0.1).  To allow an additional ip address to connect to the
kernel, use the option -a (or --allow):

    ipkernel --port 10106 --allow 168.169.170.171:192.169.0.1

To allow (deny) additional hosts to connect to the kernel see the allow (deny)
method of the RemoteKernel or InteractiveCluster classes.

The basic kernel does not support interactive calls to GUI toolkits (tk, wx,
qt, Cocoa, etc.).  This is because each GUI toolkit has its own event loop that 
must be integrated with the event loop of the kernel (which uses twisted).  

To allow the interactive use of GUI toolkits, special purpose kernels are 
offered.  Currently, we have implemented a kernel that integrates with wx.
To start this kernel, use ipkernelwx rather than ipkernel in the above 
command.  The GUI kernel accept the same command line options.  On Mac OS X
the GUI kernels must be started with the command pythonw rather than python.

NOTE: Do not run the GUI kernel unless you really need it.  This is because
the GUI kernel lacks some of the features of the basic kernel.  Most importantly
the basic kernel is multithreaded and has a queue, whereas the GUI kernels have
only a single user thread and no queue.  The queue allow multiple python 
commands to be sent to the kernel while previous commands are still executing.

== Monitoring the kernels ==

To monitor the stdin, stdout and stderr of the kernels, you must start a
ResultGatherer class.  This class is bound to a UDP port and receives UDP
datagrams from the kernels when results are ready.  To start a ResultGatherer
run the following command from the command line:

	ipresults

This will start a ResultGatherer bound to port 10104.  To change the port,
use the -p options:

	ipresults -p 10101

Once a ResultGatherer is running, you must notify the kernel that it
should send results to the ResultGatherer.  This is done using the notify()
method of the RemoteKernel or InteractiveCluster class.  

See below for examples of this.

== Using the kernel ==

The kernel interface is implemented in the kernelclient.py module.  This module
contains two main classes that allow the user to interact with the kernel:
RemoteKernel and InteractiveCluster.  This README focuses on parallel 
computations using the InteractiveCluster class, but the interface for working
with a single kernel (RemoteKernel) is almost identical.

==== Create an InteractiveCluster object ===

Begin by creating an InteractiveCluster object in ipython.  Then you tell the
object where two kernels are running and what ResultGatherer the kernels should
be notifying of results:

    In [1]: from ipython1.kernel1p.kernelclient import *

    In [2]: ic = InteractiveCluster()

    In [3]: ic.start([('127.0.0.1',10105),('127.0.0.1',10106)])
    Connecting to kernel:  ('127.0.0.1', 10105)
    Connecting to kernel:  ('127.0.0.1', 10106)
    Out[3]: True

    In [4]: ic.notify(('127.0.0.1',10104))

Now the InteractiveCluster object is ready to use.  If there is a problem 
connecting to the kernels, you either the kernels are not actually running
or you have a networking problems (like a closed firewall).

=== Executing Commands on the kernels ===

Python commands can be executed on the kernels using the execute() method:

    In [5]: ic.execute('a = 5')             # a = 5 on all kernels

    In [6]: ic.execute('b = 10')            # b = 10 on all kernels

    In [7]: ic.execute('c = 30',0)          # c = 30 on kernel 0

    In [8]: ic.execute('c = 40',1)          # d = 40 on kernel 1

You can also access individual kernsl using a list syntax:

    In [9]: ic[0].execute('d = 10')         # Same as execute('d=10',0)

Lastly, there are ipython magics for "parallel execution":

    In [10]: %px c = 30                     # Like execute('c = 30')
    Executing command on cluster

To have every command entered automatically prefixed by %px, enter 
autoparallel mode:

    In [11]: %autopx
    Auto Parallel Enabled

    In [12]: a = 40

    In [13]: b = 40

    In [14]: c = a + b

    In [15]: %autopx
    Auto Parallel Disabled

Every command entered while in autoparallel mode is executed on all kernels.

If you have more that one InteractiveCluster object, you can make a given one 
active for the %px magics using the activate command on the cluster:

    In [16]: ic.activate()

=== Moving python object around ===

In addition to being able to execute python code on the kernels, you can move
arbitrary (OK, not arbitrary, the objects need to be pickleable) python
objects around.  This is done using the push() and pull() methods:

    In [17]: ic.push('a',10)            # Send 10 to all kernels as 'a'

    In [18]: ic.pull('a')               # Pull 'a' back from all kernels
    Out[18]: [10, 10]

    In [19]: ic.pull('q')               # q is not defined
    Out[19]: [<NotDefined: q>, <NotDefined: q>]

In this form, push() acts like an MPI broadcast and pull acts like an MPI 
gather.  But push and pull support a much richer interface for more complicated
data movement:

    In [20]: ic.push('a',10,0)          # Push to only kernel 0
    
    In [21]: ic.push('a',20,1)          # Push to only kernel 1

    In [22]: ic.pull('a')               # Now gather from both
    Out[22]: [10, 20]

You can also give push and pull a list of kernel to work with:

    In [23]: ic.push('a',10,[0,1])

    In [24]: ic.pull('a',[0,1])
    Out[24]: [10, 10]

You can also use the list syntax:

    In [25]: ic[0].push('a',10)
    Out[25]: True

    In [26]: ic[0].pull('a')
    Out[26]: 10

Best of all, push and pull have convenient dictionary style interfaces:

    In [27]: ic['a'] = 10

    In [28]: ic['a']
    Out[28]: [10, 10]

    In [29]: ic[0]['b'] = 20

    In [30]: ic[1]['b'] = 20

    In [31]: ic['b']
    Out[31]: [20, 20]

You can partition and distribute a python sequence (an MPI scatter) to the 
kernels by pushing a Scatter object initialized with the sequence:

    In [5]: ic.push('a',Scatter(range(10)))

    In [6]: ic.pull('a')
    Out[6]: [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]

Or use the dictionary interface:

    In [7]: ic['a'] = Scatter(range(10))

By default, Scatter treats unit length sequences as lists:

    In [7]: ic['a'] = Scatter(range(2))

    In [8]: ic['a']
    Out[8]: [[0], [1]]

To scatter length one lists as scalars, set the flatten flag on the Scatter
object:

    In [9]: ic['a'] = Scatter(range(2),True)

    In [10]: ic['a']
    Out[10]: [0, 1]


NOTE:  While you can do things like ic[0]['a'] = ic[1]['b'], these types of
       data movements have not been optimized.  Currently the python object
       would come back to you  from kernel 1 and then be sent out to kernel 
       0.  Eventually we will implement a move() method for moving objects
       directly from one kernel to another.

NOTE:  Because push and pull use the pickle module, you cannot push and pull
       python functions to the kernels and back.

=== The map and parallelize commands ===

With the basic commands (push, pull and execute) higher level constructs
can be build.  The map() and parallelize() methods of InteractiveCluster are
examples of this.

The map() method work just like the builtin python map, but the calling 
convention differs slightly.

    In [14]: map(lambda x: x*x,range(10))
    Out[14]: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

The same thing on the cluster is called by giving the function to call
as a string:

    In [15]: ic.map('lambda x: x*x',range(10))
    Out[15]: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

But, in this case, the sequence range(10) is scattered amongst the kernels
and then each kernel maps part of the list in parallel.  This is the most 
trivial way of parallelizing a simple algorithm. 

There are a number of similar ways of accomplishing the same thing:

    In [23]: ic.push('a', Scatter(range(10)))

    In [24]: %px b = [x*x for x in a]
    Executing command on cluster

    In [25]: ic.pull('a',flatten=True)
    Out[25]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

Or, there is a powerful VectorFunction object:

    In [26]: f = ic.parallelize('lambda x: x*x')

    In [27]: f(range(10))
    Out[27]: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

The function f is a ParallelFunction object that exists in the local namespace.
It basically is a wrapper for the parallelized map() method of the cluster.

NOTE:  The functions used by map and parallelize must already be defined in the
       namespace of each kernel!  You cannot pass functions to the kernels.


=== Other commands ===

You can reset the kernel's namespaces:

    In [32]: ic.reset()

You can disconnect from the kernels:

    In [34]: ic.disconnect() 

Calling any method on the InteractiveCluster object that requires a kernel
connection will cause an automatic reconnect:

    In [35]: ic.execute('a = 5')
    Connecting to kernel:  ('127.0.0.1', 10105)
    Connecting to kernel:  ('127.0.0.1', 10106)

To allow or deny a specific ip address to connect to the cluster use
the allow() and deny() methods:

    In [36]: ic.allow('121.122.123.124')

    In [37]: ic.deny('121.122.123.124')

To kill the kernels for good, use kill():

    In [38]: ic.kill()

